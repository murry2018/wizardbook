### 연습 1.20 (p. 64)

```
gcd 206 40
if (= 40 0) 206 (gcd 40 (remainder 206 40))
if (= (remainder 206 40) 0) 40 (gcd (remainder 206 40) (remainder 40 (remainder 206 40)))
...
```

정의대로 계산법을 이용하면 계산 단계를 한 번 거칠 때마다 remainder을 세 배씩 더 계산하게 된다.

그러나 실제 정의대로 계산법을 채택하고 있는 언어들은 순수 함수의 참조 투명성이라는 성질을 이용하여, 한 번 계산된 결과를 동일한 식에 대해 공유한다. 이런 최적화 기술을 사용할 경우, gcd의 계산량은 정의대로 계산법이나 인자먼저 계산법이나 별 차이가 없게 된다. Haskell이 그런 언어들 가운데 하나이다.

### 연습 1.21 (p. 68)

```
(smallest_divisor 199) ;; => 199
(smallest_divisor 1999) ;; => 1999
(smallest_divisor 19999) ;; => 7
```

### 연습 1.22 (p. 68)

내가 쓰는 스킴 구현(Chicken scheme)에서는 `runtime` 함수가 없어서, 그 대신 `current-milliseconds`라는 함수를 이용했다.

```scheme
(import (chicken time))
(define (runtime) (current-milliseconds))
```

`search-for-prmies`는 다음과 같이 구현할 수 있다.

```scheme
(define (test-prime-and-continue begin end)
  (timed-prime-test begin)
  (search-for-primes (1+ begin) end))
(define (search-for-primes begin end)
  (if (< begin end)
      (test-prime-and-continue begin end)))
```

그러나 의미 있는 시간 비교가 되지 않아, 각 소수에 대해 만 번씩 반복하여 측정하였다.

| 구간 | 평균 시간(ms) |
|---|---|
| 1000~ | 149 |
| 10000~ | 463.3 |
| 100000~ | 1470.6 |
| 1000000~ | 4951.6 |

- 149√10 = 471.18 (상대오차 1.6%)
- 463.3√10 = 1465.08 (상대오차 0.4%)
- 1470.6√10 = 4650.45 (상대오차 6.08%)

오차범위 10% 이내에서 √n 시간 복잡도에 들어맞는다.

### 연습 1.23 (p.69)

`next`는 다음과 같이 짰다.

```scheme
(define (next n) (if (= 2 n) 3 (+ n 2)))
```

이것을 이용하면 검사 수가 절반이 되었으니 이론 상으로는 2배 빨라지는 것이 맞다. 그러나 실제 실험 결과 100 언저리의 구간에서는 1.5배, 1000 언저리의 구간에서는 1.75배, 10000 언저리 구간에서는 1.76배, 100000 언저리 구간에서는 1.83배 빨라진다. 아무래도 분기나 함수 호출의 오버헤드 탓에 줄어들지 않는 시간 비용이 존재하는 것으로 보인다. 소수 검사 시작점을 3으로 두고 분기를 없애면(즉 next 함수가 즉시 2를 더한 값을 내보내도록 한다면) 시간 차이가 더 줄어든다는 결과를 스터디원이 알려주었다.

### 연습 1.24 (p. 70)

1000000(백만) 언저리 소수와 1000언저리 소수에 대해 페르마 검사를 하는 비용은 이론상 1000을 밑으로하는 로그에 대해 log(1000^2)을 한 것으로 2배 차이가 되어야 맞다. 그러나 실제로는 이것보다 적은 시간 비용이 들었다. 이유는 모르겠다.. 그래서 다른 결과와도 비교해보았다.

| 비교 구간 | 이론상 시간 차이 | 실제 시간 차이 |
|---|---|---|
| 1000, 100만 | 2배 | 1.625배 |
| 10000, 100만 | 1.5배 | 1.35배 |
| 10만, 100만 | 1.2배 | 1.13배 |
| 1억, 1백억 | 1.25배 | 1.40배 |
| 1백억, 1조 | 1.2배 | 1.27배 |

대략적으로 log n 시간복잡도로 증가하는 것을 알 수 있으나, 아주 정확히 일치하지는 않는다. 1백억이 넘어갈 때부터 이론값과 실험값 추이가 뒤집어지는 것을 보아 표현형과 연관이 있으리라 추측 하고는 있다.
